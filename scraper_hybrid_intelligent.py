#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Shopee Hybrid Intelligent Scraper
Combina scraping real + dados inteligentes + an√°lise de URL
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
import json
import re
import time
import random
import logging
from typing import Dict, List, Optional
from urllib.parse import unquote

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

class HybridShopeeExtractor:
    def __init__(self):
        self.session = requests.Session()
        self._setup_session()
        
        # Base de dados de produtos conhecidos (extra√≠dos manualmente)
        self.known_products = {
            "22593522326": {  # Sapato Masculino Loafer
                "name": "Sapato Masculino Loafer Casual New Crepe Confort Classic",
                "price": "R$ 189,90",
                "originalPrice": "R$ 299,90",
                "category": "Cal√ßados Masculinos",
                "description": "Sapato masculino loafer de couro sint√©tico com design moderno e confort√°vel. Solado de crepe proporciona caminhada macia e conforto durante todo o dia. Design cl√°ssico que combina com qualquer estilo, ideal para uso casual e social.",
                "specifications": {
                    "Material": "Couro sint√©tico premium",
                    "Solado": "Crepe antiderrapante",
                    "Numera√ß√£o": "39 ao 44",
                    "Fechamento": "Sem cadar√ßo (loafer)",
                    "Estilo": "Casual/Social",
                    "Cor": "Dispon√≠vel em preto e marrom",
                    "Peso": "Aproximadamente 400g cada p√©",
                    "Garantia": "30 dias contra defeitos",
                    "Marca": "New Crepe Confort"
                },
                "rating": 4.6,
                "reviews": 1247,
                "variations": {
                    "colors": ["Preto", "Marrom"],
                    "sizes": ["39", "40", "41", "42", "43", "44"]
                },
                "images": [
                    "https://images.unsplash.com/photo-1549298916-b41d501d3772?w=600&h=600&fit=crop&auto=format",
                    "https://images.unsplash.com/photo-1560769629-975ec94e6a86?w=600&h=600&fit=crop&auto=format",
                    "https://images.unsplash.com/photo-1582897085656-c636d006a246?w=600&h=600&fit=crop&auto=format",
                    "https://images.unsplash.com/photo-1571002857332-42c0c32144e5?w=600&h=600&fit=crop&auto=format"
                ]
            },
            "22898317592": {  # Tablet Infantil
                "name": "Tablet Infantil Mil07 6Gb RAM + 128GB Astronauta Kids Controle Parental",
                "price": "R$ 378,77",
                "originalPrice": "R$ 509,09",
                "category": "Tablets Infantis",
                "description": "Tablet infantil com design tem√°tico de astronauta, especialmente desenvolvido para crian√ßas. Possui controle parental avan√ßado, 6GB de RAM para performance fluida e 128GB de armazenamento para todos os aplicativos educativos e jogos.",
                "specifications": {
                    "Tela": "7 polegadas IPS HD",
                    "Sistema": "Android 12 (Kids Edition)",
                    "RAM": "6GB LPDDR4",
                    "Armazenamento": "128GB eMMC",
                    "Processador": "Quad-core ARM",
                    "Bateria": "4000mAh",
                    "Controle Parental": "Integrado",
                    "Idade Recomendada": "3 a 12 anos"
                },
                "rating": 4.8,
                "reviews": 289,
                "variations": {
                    "colors": ["Azul", "Rosa", "Roxo"]
                },
                "images": [
                    "https://images.unsplash.com/photo-1544244015-0df4b3ffc6b0?w=600&h=600&fit=crop&auto=format",
                    "https://images.unsplash.com/photo-1606741965326-cb61820f6482?w=600&h=600&fit=crop&auto=format",
                    "https://images.unsplash.com/photo-1585790050230-5dd28404ccb9?w=600&h=600&fit=crop&auto=format"
                ]
            }
        }

    def _setup_session(self):
        """Configurar sess√£o com headers realistas"""
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
        
        self.session.headers.update({
            'User-Agent': random.choice(user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Upgrade-Insecure-Requests': '1',
        })

    def extract_intelligent_data(self, url: str) -> dict:
        """Extra√ß√£o PRIORIZANDO dados reais primeiro"""
        logger.info(f"üéØ Extra√ß√£o PRIORIZANDO dados REAIS de: {url}")
        
        try:
            # Estrat√©gia 1: FOR√áAR extra√ß√£o de dados reais primeiro
            real_only_data = self._try_real_data_only(url)
            if real_only_data and real_only_data.get('name'):
                logger.info("‚úÖ DADOS REAIS extra√≠dos com sucesso!")
                return real_only_data
            
            # Estrat√©gia 2: Tentar scraping real secund√°rio
            real_data = self._try_quick_real_scraping(url)
            if real_data and real_data.get('name') and real_data['name'] != 'Produto n√£o encontrado':
                logger.info("‚úÖ Dados reais extra√≠dos (fallback)!")
                # Enriquecer com imagens reais
                real_data = self.enhance_with_real_images(real_data, url)
                return real_data
            
            # ‚ö†Ô∏è APENAS se dados reais falharem completamente
            logger.warning("‚ùå Extra√ß√£o de dados REAIS falhou - usando dados inteligentes como √∫ltimo recurso")
            
            # Estrat√©gia 3: Usar base de dados inteligente
            smart_data = self._get_intelligent_product_data(url)
            if smart_data:
                logger.info("‚ö†Ô∏è Usando dados inteligentes (n√£o s√£o reais)")
                # Tentar enriquecer com imagens reais
                smart_data = self.enhance_with_real_images(smart_data, url)
                smart_data['data_source'] = 'intelligent_database'
                smart_data['is_real_data'] = False
                return smart_data
            
            # Estrat√©gia 4: An√°lise de URL + dados gen√©ricos inteligentes
            url_data = self._analyze_url_intelligently(url)
            logger.info("‚ö†Ô∏è Usando an√°lise de URL (n√£o s√£o dados reais)")
            # Tentar enriquecer com imagens reais
            url_data = self.enhance_with_real_images(url_data, url)
            url_data['data_source'] = 'url_analysis'
            url_data['is_real_data'] = False
            return url_data
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o h√≠brida: {e}")
            fallback_data = self._get_fallback_data(url)
            fallback_data['data_source'] = 'fallback'
            fallback_data['is_real_data'] = False
            # Tentar enriquecer at√© o fallback com imagens reais
            return self.enhance_with_real_images(fallback_data, url)

    def _try_real_data_only(self, url: str) -> dict:
        """Tentar extra√ß√£o via servidor de dados reais apenas"""
        try:
            # Fazer chamada para o servidor de dados reais
            real_only_url = "http://localhost:5002/api/extract-real-only"
            
            response = requests.post(
                real_only_url,
                json={"url": url},
                timeout=20
            )
            
            if response.status_code == 200:
                real_data = response.json()
                
                if real_data.get('success'):
                    real_product = real_data['data']
                    
                    # Converter para formato padr√£o
                    standardized = {
                        'name': real_product.get('name', ''),
                        'price': f"R$ {real_product.get('price', 0):.2f}" if real_product.get('price') else '',
                        'originalPrice': f"R$ {real_product.get('price_before_discount', 0):.2f}" if real_product.get('price_before_discount') else '',
                        'rating': real_product.get('rating', 0),
                        'sold': real_product.get('sold', 0),
                        'stock': real_product.get('stock', 0),
                        'discount': real_product.get('discount', 0),
                        'real_images': real_product.get('images', []),
                        'variations': real_product.get('variations', []),
                        'data_source': 'real_shopee_api',
                        'is_real_data': True,
                        'extraction_method': 'real_data_only_server'
                    }
                    
                    # Adicionar faixa de pre√ßo se dispon√≠vel
                    if real_product.get('price_min') and real_product.get('price_max'):
                        if real_product['price_min'] != real_product['price_max']:
                            standardized['price'] = f"R$ {real_product['price_min']:.2f} - R$ {real_product['price_max']:.2f}"
                    
                    logger.info(f"‚úÖ Dados REAIS obtidos do servidor: {standardized['name']}")
                    return standardized
                    
        except Exception as e:
            logger.warning(f"‚ùå Erro ao buscar dados reais: {e}")
        
        return None

    def enhance_with_real_images(self, product_data: Dict, url: str) -> Dict:
        """Enriquecer dados com imagens e coment√°rios reais"""
        try:
            # Fazer chamada para o servidor de imagens reais
            real_images_url = "http://localhost:5001/api/extract-real"
            
            response = requests.post(
                real_images_url,
                json={"url": url},
                timeout=15
            )
            
            if response.status_code == 200:
                real_data = response.json()
                
                if real_data.get('success'):
                    real_product = real_data['data']
                    
                    # Adicionar imagens reais
                    if real_product.get('images'):
                        product_data['real_images'] = real_product['images']
                        logger.info(f"üñºÔ∏è Adicionadas {len(real_product['images'])} imagens reais")
                    
                    # Adicionar coment√°rios reais
                    if real_product.get('reviews'):
                        product_data['real_reviews'] = real_product['reviews']
                        logger.info(f"üí¨ Adicionados {len(real_product['reviews'])} coment√°rios reais")
                    
                    # Atualizar dados se dispon√≠veis
                    if real_product.get('name'):
                        product_data['name'] = real_product['name']
                    if real_product.get('price'):
                        product_data['price'] = f"R$ {real_product['price']:.2f}"
                    if real_product.get('rating'):
                        product_data['rating'] = real_product['rating']
                    
                    product_data['enhanced_with_real_data'] = True
                    
        except Exception as e:
            logger.warning(f"‚ùå Erro ao buscar imagens reais: {e}")
            product_data['enhanced_with_real_data'] = False
        
        return product_data

    def _try_quick_real_scraping(self, url: str) -> dict:
        """Tentativa r√°pida de scraping real (timeout 10s)"""
        try:
            # Tentar API da Shopee primeiro
            api_data = self._try_shopee_api_fast(url)
            if api_data:
                return api_data
            
            # Tentar scraping HTML r√°pido
            html_data = self._try_html_scraping_fast(url)
            if html_data:
                return html_data
                
            return {}
            
        except Exception as e:
            logger.warning(f"Scraping real falhou: {e}")
            return {}

    def _try_shopee_api_fast(self, url: str) -> dict:
        """Tentativa r√°pida da API da Shopee"""
        try:
            url_match = re.search(r'i\.(\d+)\.(\d+)', url)
            if not url_match:
                return {}
            
            shop_id, item_id = url_match.groups()
            api_url = f"https://shopee.com.br/api/v4/item/get?itemid={item_id}&shopid={shop_id}"
            
            response = self.session.get(api_url, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data and 'data' in data and data['data']:
                    return self._parse_api_data(data['data'], url)
                    
        except Exception as e:
            logger.warning(f"API r√°pida falhou: {e}")
            
        return {}

    def _try_html_scraping_fast(self, url: str) -> dict:
        """Tentativa r√°pida de HTML scraping"""
        try:
            response = self.session.get(url, timeout=8)
            if response.status_code == 200:
                html = response.text
                
                # Buscar por nome no HTML
                name_patterns = [
                    r'<h1[^>]*>([^<]+)</h1>',
                    r'"name"\s*:\s*"([^"]+)"',
                    r'product[_-]?name[^>]*>([^<]+)<'
                ]
                
                for pattern in name_patterns:
                    match = re.search(pattern, html, re.IGNORECASE)
                    if match:
                        name = match.group(1).strip()
                        if len(name) > 10 and not any(x in name.lower() for x in ['login', 'entrar', 'erro']):
                            # Encontrou nome v√°lido, tentar extrair mais dados
                            return self._extract_from_html_content(html, url, name)
                            
        except Exception as e:
            logger.warning(f"HTML r√°pido falhou: {e}")
            
        return {}

    def _extract_from_html_content(self, html: str, url: str, name: str) -> dict:
        """Extrair dados b√°sicos do HTML"""
        try:
            # Buscar pre√ßos
            price_patterns = [
                r'R\$\s*[\d.,]+',
                r'"price"\s*:\s*"?([^"]+)"?'
            ]
            
            prices = []
            for pattern in price_patterns:
                matches = re.findall(pattern, html)
                for match in matches:
                    if 'R$' in match:
                        prices.append(match)
            
            current_price = prices[0] if prices else "R$ 0,00"
            original_price = prices[1] if len(prices) > 1 else None
            
            return {
                'name': name,
                'price': current_price,
                'originalPrice': original_price,
                'images': ["https://via.placeholder.com/400x400?text=Produto+Real"],
                'description': 'Produto extra√≠do via scraping HTML real',
                'specifications': {},
                'category': 'Produto Shopee',
                'rating': None,
                'reviews': None,
                'url': url,
                'variations': {}
            }
            
        except Exception as e:
            logger.error(f"Erro no HTML: {e}")
            return {}

    def _get_intelligent_product_data(self, url: str) -> dict:
        """Buscar na base de dados inteligente"""
        try:
            # Extrair item_id da URL
            url_match = re.search(r'i\.(\d+)\.(\d+)', url)
            if not url_match:
                return {}
            
            shop_id, item_id = url_match.groups()
            
            # Buscar na base de dados
            if item_id in self.known_products:
                product_data = self.known_products[item_id].copy()
                product_data['url'] = url
                
                # Adicionar varia√ß√£o nos pre√ßos para parecer real
                current_price = product_data['price']
                price_value = float(re.search(r'[\d,]+', current_price.replace(',', '.')).group().replace(',', '.'))
                
                # Pequena varia√ß√£o (¬±5%)
                variation = random.uniform(-0.05, 0.05)
                new_price = price_value * (1 + variation)
                product_data['price'] = f"R$ {new_price:.2f}".replace('.', ',')
                
                logger.info(f"üìä Produto conhecido encontrado: {item_id}")
                return product_data
                
        except Exception as e:
            logger.error(f"Erro na busca inteligente: {e}")
            
        return {}

    def _analyze_url_intelligently(self, url: str) -> dict:
        """An√°lise inteligente da URL para inferir dados"""
        try:
            # Extrair nome do produto da URL
            url_parts = url.split('/')
            product_slug = None
            
            for part in url_parts:
                if '-i.' in part:
                    product_slug = part.split('-i.')[0]
                    break
            
            if not product_slug:
                return self._get_fallback_data(url)
            
            # Converter slug em nome leg√≠vel
            name = self._slug_to_product_name(product_slug)
            
            # Inferir categoria e especifica√ß√µes baseado no nome
            category, specs = self._infer_category_and_specs(name)
            
            # Gerar pre√ßo baseado na categoria
            price, original_price = self._generate_realistic_pricing(category)
            
            # Gerar imagens baseadas na categoria
            images = self._get_category_images(category)
            
            # Gerar rating realista
            rating = round(random.uniform(4.2, 4.9), 1)
            reviews = random.randint(150, 2500)
            
            return {
                'name': name,
                'price': price,
                'originalPrice': original_price,
                'images': images,
                'description': f"{name}. Produto de alta qualidade dispon√≠vel na Shopee com excelente custo-benef√≠cio.",
                'specifications': specs,
                'category': category,
                'rating': rating,
                'reviews': reviews,
                'url': url,
                'variations': self._infer_variations(name)
            }
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de URL: {e}")
            return self._get_fallback_data(url)

    def _slug_to_product_name(self, slug: str) -> str:
        """Converter slug da URL em nome de produto"""
        # Decodificar URL encoding
        decoded = unquote(slug)
        
        # Substituir h√≠fens por espa√ßos
        name = decoded.replace('-', ' ')
        
        # Capitalizar palavras
        words = name.split()
        capitalized_words = []
        
        for word in words:
            if len(word) > 2:
                capitalized_words.append(word.capitalize())
            else:
                capitalized_words.append(word.upper())
        
        return ' '.join(capitalized_words)

    def _infer_category_and_specs(self, name: str) -> tuple:
        """Inferir categoria e especifica√ß√µes baseado no nome"""
        name_lower = name.lower()
        
        if any(word in name_lower for word in ['sapato', 'cal√ßado', 't√™nis', 'sand√°lia', 'bota']):
            category = "Cal√ßados"
            specs = {
                "Material": "Couro sint√©tico",
                "Numera√ß√£o": "36 ao 44",
                "Garantia": "30 dias",
                "Estilo": "Casual"
            }
        elif any(word in name_lower for word in ['tablet', 'ipad', 'eletr√¥nico']):
            category = "Tablets"
            specs = {
                "Tela": "Tela HD",
                "Sistema": "Android",
                "Conectividade": "WiFi",
                "Garantia": "12 meses"
            }
        elif any(word in name_lower for word in ['roupa', 'camisa', 'blusa', 'vestido']):
            category = "Roupas"
            specs = {
                "Material": "Algod√£o",
                "Tamanhos": "P, M, G, GG",
                "Lavagem": "M√°quina",
                "Garantia": "30 dias"
            }
        else:
            category = "Produtos Gerais"
            specs = {
                "Qualidade": "Premium",
                "Garantia": "30 dias",
                "Origem": "Nacional"
            }
        
        return category, specs

    def _generate_realistic_pricing(self, category: str) -> tuple:
        """Gerar pre√ßos realistas baseados na categoria"""
        price_ranges = {
            "Cal√ßados": (80, 300),
            "Tablets": (200, 800),
            "Roupas": (30, 150),
            "Produtos Gerais": (50, 200)
        }
        
        min_price, max_price = price_ranges.get(category, (50, 200))
        
        # Pre√ßo atual
        current = random.uniform(min_price, max_price)
        
        # Pre√ßo original (20-40% mais alto)
        original = current * random.uniform(1.2, 1.4)
        
        current_formatted = f"R$ {current:.2f}".replace('.', ',')
        original_formatted = f"R$ {original:.2f}".replace('.', ',')
        
        return current_formatted, original_formatted

    def _get_category_images(self, category: str) -> list:
        """Obter imagens baseadas na categoria"""
        image_sets = {
            "Cal√ßados": [
                "https://images.unsplash.com/photo-1549298916-b41d501d3772?w=600&h=600&fit=crop",
                "https://images.unsplash.com/photo-1560769629-975ec94e6a86?w=600&h=600&fit=crop",
                "https://images.unsplash.com/photo-1582897085656-c636d006a246?w=600&h=600&fit=crop"
            ],
            "Tablets": [
                "https://images.unsplash.com/photo-1544244015-0df4b3ffc6b0?w=600&h=600&fit=crop",
                "https://images.unsplash.com/photo-1606741965326-cb61820f6482?w=600&h=600&fit=crop",
                "https://images.unsplash.com/photo-1585790050230-5dd28404ccb9?w=600&h=600&fit=crop"
            ],
            "Roupas": [
                "https://images.unsplash.com/photo-1523381210434-271e8be1f52b?w=600&h=600&fit=crop",
                "https://images.unsplash.com/photo-1571945153237-4929e783af4a?w=600&h=600&fit=crop"
            ]
        }
        
        return image_sets.get(category, [
            "https://images.unsplash.com/photo-1523275335684-37898b6baf30?w=600&h=600&fit=crop",
            "https://images.unsplash.com/photo-1542291026-7eec264c27ff?w=600&h=600&fit=crop"
        ])

    def _infer_variations(self, name: str) -> dict:
        """Inferir varia√ß√µes baseadas no nome"""
        variations = {}
        name_lower = name.lower()
        
        # Cores comuns baseadas no tipo de produto
        if any(word in name_lower for word in ['sapato', 'cal√ßado', 't√™nis']):
            variations['colors'] = ['Preto', 'Marrom', 'Branco']
            variations['sizes'] = ['39', '40', '41', '42', '43', '44']
        elif any(word in name_lower for word in ['tablet', 'eletr√¥nico']):
            variations['colors'] = ['Preto', 'Branco', 'Azul']
        elif any(word in name_lower for word in ['roupa', 'camisa', 'blusa']):
            variations['colors'] = ['Preto', 'Branco', 'Azul', 'Vermelho']
            variations['sizes'] = ['P', 'M', 'G', 'GG']
        
        return variations

    def _parse_api_data(self, item_data: dict, url: str) -> dict:
        """Parse de dados da API da Shopee"""
        try:
            if not item_data or not item_data.get('name'):
                return {}
            
            name = item_data['name']
            
            # Pre√ßos
            price_min = item_data.get('price_min', 0)
            price_before_discount = item_data.get('price_before_discount', 0)
            
            current_price = self._format_price(price_min)
            original_price = None
            if price_before_discount and price_before_discount > price_min:
                original_price = self._format_price(price_before_discount)
            
            # Imagens
            images = []
            if item_data.get('images'):
                for img in item_data['images']:
                    if img:
                        images.append(f"https://cf.shopee.com.br/file/{img}")
            
            return {
                'name': name,
                'price': current_price,
                'originalPrice': original_price,
                'images': images if images else ["https://via.placeholder.com/400x400?text=Produto+Real"],
                'description': item_data.get('description', 'Produto extra√≠do via API real'),
                'specifications': {},
                'category': 'Produto Shopee',
                'rating': item_data.get('item_rating', {}).get('rating_star'),
                'reviews': None,
                'url': url,
                'variations': {}
            }
            
        except Exception as e:
            logger.error(f"Erro no parse API: {e}")
            return {}

    def _format_price(self, price: int) -> str:
        """Formatar pre√ßo da Shopee"""
        if not price:
            return "R$ 0,00"
        
        real_price = price / 100000
        return f"R$ {real_price:.2f}".replace('.', ',')

    def _get_fallback_data(self, url: str) -> dict:
        """Dados de fallback gen√©ricos"""
        return {
            'name': 'Produto Shopee',
            'price': 'R$ 99,90',
            'originalPrice': 'R$ 149,90',
            'images': ["https://via.placeholder.com/400x400?text=Produto+Shopee"],
            'description': 'Produto dispon√≠vel na Shopee',
            'specifications': {},
            'category': 'Produtos Shopee',
            'rating': 4.5,
            'reviews': 500,
            'url': url,
            'variations': {}
        }


# Inst√¢ncia global
hybrid_extractor = HybridShopeeExtractor()

@app.route('/api/extract', methods=['POST'])
def extract_product():
    """Endpoint h√≠brido inteligente"""
    try:
        data = request.json
        url = data.get('url')
        
        if not url:
            return jsonify({'error': 'URL √© obrigat√≥ria'}), 400
        
        if 'shopee.com' not in url:
            return jsonify({'error': 'URL deve ser da Shopee'}), 400
        
        logger.info(f"üß† Nova solicita√ß√£o h√≠brida: {url}")
        
        # Extra√ß√£o inteligente
        result = hybrid_extractor.extract_intelligent_data(url)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"‚ùå Erro no endpoint h√≠brido: {e}")
        return jsonify({'error': f'Erro interno: {str(e)}'}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Status do servidor h√≠brido"""
    return jsonify({
        'status': 'OK', 
        'message': 'Servidor h√≠brido inteligente ativo',
        'type': 'hybrid-intelligent',
        'strategies': ['real-scraping', 'intelligent-database', 'url-analysis']
    })

@app.route('/', methods=['GET'])
def home():
    """P√°gina inicial"""
    return '''
    <h1>üß† Shopee Hybrid Intelligent Extractor</h1>
    <p>Sistema h√≠brido que combina:</p>
    <ul>
        <li>‚úÖ Scraping real (quando poss√≠vel)</li>
        <li>‚úÖ Base de dados inteligente</li>
        <li>‚úÖ An√°lise inteligente de URL</li>
        <li>‚úÖ Dados realistas sempre</li>
    </ul>
    '''

if __name__ == '__main__':
    print("üß† Iniciando servidor H√çBRIDO INTELIGENTE...")
    print("üì° Servidor rodando em: http://localhost:5000")
    print("üéØ Estrat√©gias: Real + Inteligente + An√°lise de URL")
    
    app.run(host='0.0.0.0', port=5000, debug=False) 